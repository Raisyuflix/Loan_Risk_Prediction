# -*- coding: utf-8 -*-
"""Loan_Risk_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13DOSbleMJd_TBpxaFvbyHNiQ7ZAl7Ycv

# Import Library
"""

from google.colab import drive
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import kendalltau
# preprocessing
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder
from sklearn.preprocessing import MinMaxScaler



# Modeling
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay,f1_score, accuracy_score, precision_score, recall_score,make_scorer
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV

# Model Saving
import pickle
import warnings

warnings.filterwarnings('ignore')

"""# Data Loading"""

drive.mount('/content/gdrive')

#Call the existing data set
df = pd.read_csv('/content/gdrive/My Drive/Data_latih/loan_data_2007_2014.csv')

df

df.info()

"""Based on this info, some column will be droped. Columns that will be droped are :
- Id: too many distinct columns
- member id: This column simply displays the row index.
- desc: This column's missing value must be dropped because it is excessive.
- mths_since_last_delinq: This column's missing value must be dropped because it is excessive.
- The mths_since_last_record variable This column's missing value must be dropped because it is excessive.
- next_pymnt_d: This column's missing value must be dropped because it is excessive.
- mths_since_last_major_derog : This column's missing value must be dropped because it is excessive.
- annual_inc_joint: This column's missing value must be dropped because it is excessive.
- dti_joint : This column's missing value must be dropped because it is excessive.
- verification_status_joint : This column's missing value must be dropped because it is excessive.
- tot_coll_amt : This column's missing value must be dropped because it is excessive.
- tot_cur_bal : This column's missing value must be dropped because it is excessive.
- open_acc_6m : This column's missing value must be dropped because it is excessive.
- open_il_6m : This column's missing value must be dropped because it is excessive.
- open_il_12m : This column's missing value must be dropped because it is excessive.
- open_il_24m : This column's missing value must be dropped because it is excessive.
- mths_since_rcnt_il : This column's missing value must be dropped because it is excessive.
- total_bal_il : This column's missing value must be dropped because it is excessive.
- il_util : This column's missing value must be dropped because it is excessive.
- open_rv_12m : This column's missing value must be dropped because it is excessive.
- open_rv_24m : This column's missing value must be dropped because it is excessive.
- max_bal_bc : This column's missing value must be dropped because it is excessive.
- all_util : This column's missing value must be dropped because it is excessive.
- total_rev_hi_lim : This column's missing value must be dropped because it is excessive.
- inq_fi : This column's missing value must be dropped because it is excessive.
- total_cu_tl : This column's missing value must be dropped because it is excessive.
- inq_last_12m : This column's missing value must be dropped because it is excessive.

"""

droped_column= ['Unnamed: 0','id', 'member_id' ,'desc', 'mths_since_last_delinq', 'mths_since_last_record',  'next_pymnt_d', 'mths_since_last_major_derog',
'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m',
'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',
'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl',  'inq_last_12m' ]

df = df.drop(droped_column, axis=1)
df

df.info()

"""There will be some missing values dropped, but not their columns. This is possible as the total amount of missing values in those columns is manageable and may be disregarded."""

df_fix = df.dropna()
df_fix = df_fix.reset_index(drop=True)
df_fix

df_fix.info()

df_fix.columns

columns = [ 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',
       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',
       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',
       'issue_d', 'loan_status', 'pymnt_plan', 'url', 'purpose', 'title',
       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',
       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',
       'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv',
       'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',
       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',
       'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d',
       'collections_12_mths_ex_med', 'policy_code', 'application_type',
       'acc_now_delinq']

cardinal = []
for i in columns:
    nunique = df[i].nunique()
    type = df[i].dtypes
    print(i, nunique,type)

    if type == 'object' and nunique > 10 or nunique ==1 :
        cardinal.append(i)



cardinal

"""Based on cardinality checking, some column will be dropped causes by its cardinality. The columns that will be droped are :
- 'sub_grade'
- 'emp_title'
- 'emp_length'
- 'issue_d'
- 'url'
- 'purpose'
- 'title'
- 'zip_code'
- 'addr_state'
- 'earliest_cr_line'
- 'last_pymnt_d'
- 'last_credit_pull_d'
- 'application_type'
"""

df_final = df_fix.drop(cardinal, axis=1)
df_final = df_final.reset_index(drop=True)
df_final

df_final['loan_status'].unique()

def loan_status_risk(loan_status):
    if pd.isna(loan_status):
        pass
    elif loan_status in ['Fully Paid']:
        return 'Low Risk'
    elif loan_status in ['Current','In Grace Period']:
        return 'Medium Risk'
    else :
        return 'High Risk'

df_final['loan_risk'] = df_final['loan_status'].apply(loan_status_risk)
df_final['loan_risk']

df_final = df_final.drop(['loan_status'],axis=1)
df_final

df_final.to_csv('data_final.csv', index=False)

"""# EDA"""

df_final.columns

final_columns =['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate',
       'installment', 'grade', 'home_ownership', 'annual_inc',
       'verification_status', 'pymnt_plan', 'dti', 'delinq_2yrs',
       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',
       'total_acc', 'initial_list_status', 'out_prncp', 'out_prncp_inv',
       'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',
       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',
       'last_pymnt_amnt', 'collections_12_mths_ex_med', 'acc_now_delinq',
       'loan_risk']

col_num = []
col_cat = []

for i in final_columns:
    if df_final[i].dtypes == 'object':
        col_cat.append(i)

    else:
        col_num.append(i)

print('numerical columns are: ',col_num )
print('categorical columns are: ',col_cat)

fig,ax1 = plt.subplots(figsize=(8,8))

df_final['loan_risk'].value_counts().plot(kind='pie', autopct='%.2f%%',ax=ax1)
plt.show()

"""# Feature Engineering"""

correlation_num = []
for i in col_num:
    correlation, p_value = kendalltau(df_final['loan_risk'], df_final[i])


    if p_value <0.05 :
        correlation_num.append(i)
print('The column that has correlation with loan status are', correlation_num)

correlation_cat = []
for i in col_cat :
    tabel_korelasi = pd.crosstab(df_final['loan_risk'], df_final[i])
    tes_korelasi = stats.chi2_contingency(tabel_korelasi)
    pval = tes_korelasi.pvalue
    corr = tes_korelasi.statistic

    if i == 'loan_risk':
        pass

    elif pval < 0.05 :
        correlation_cat.append(i)
        print(i,'pvalue ;',pval,'correlation :',corr)

print('')
print('The column that has correlation with loan status are ', correlation_cat)

print('Total numerical columns that will be used on this case is ', len(correlation_num))
print('Total categorical columns that will be used on this case is ', len(correlation_cat))

# Data fixed after feature
data_final = pd.concat([df_final[correlation_num],df_final[correlation_cat],df_final['loan_risk']],axis=1)
data_final

"""# Data Preparation

## Spliting
"""

# Separating targets from features

x = data_final.drop('loan_risk',axis=1)
y = data_final['loan_risk']

# Divide data into train data and test data

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state = 12,stratify=y)

x_train_num = x_train[correlation_num]
x_train_cat = x_train[correlation_cat]

x_test_num = x_test[correlation_num]
x_test_cat = x_test[correlation_cat]

"""## Numerical Column Check"""

# Check the normality of the train data using skewness
for i in correlation_num :
    skew = x_train_num[i].skew()

    print('Skewness of', i ,'is', skew )

# Cek kenormalan data test menggunakan skewness
for i in correlation_num :
    skew = x_test_num[i].skew()

    print('Skewness of', i ,'is', skew )

# determining outlier data in train data
for i in correlation_num:
    skew = x_train_num[i].skew()

    q1 = x_train_num[i].quantile(0.25)
    q3 = x_train_num[i].quantile(0.75)
    iqr = q3-q1

    upper_boundary = q3 + (1.5*iqr)
    lower_boundary = q1 - (1.5*iqr)

    outlier = x_train_num[(x_train_num[i]>upper_boundary)|((x_train_num[i]<lower_boundary))]
    persen_outlier = len(outlier)/len(x_train_num)*100

    print('Precentage outlier of', i ,'is', persen_outlier, '%')

# determining outlier data in test data
for i in correlation_num:
    skew = x_test_num[i].skew()

    q1 = x_test_num[i].quantile(0.25)
    q3 = x_test_num[i].quantile(0.75)
    iqr = q3-q1

    upper_boundary = q3 + (1.5*iqr)
    lower_boundary = q1 - (1.5*iqr)

    outlier = x_test_num[(x_test_num[i]>upper_boundary)|((x_test_num[i]<lower_boundary))]
    persen_outlier = len(outlier)/len(x_test_num)*100

    print('Precentage outlier of', i ,'is', persen_outlier, '%')

x_train_num.isnull().sum()

x_test_num.isnull().sum()

"""## Categorical Column Check"""

x_train_cat.isnull().sum()

x_test_cat.isnull().sum()

"""# Labelling"""

for i in correlation_cat :
    print(i,data_final[i].unique())

correlation_cat

correlation_cat_ordinal = ['term','grade','pymnt_plan','initial_list_status']
correlation_cat_non_ordinal = ['verification_status','pymnt_plan']

"""# Pipeline"""

num_pipeline = Pipeline([
    ('Scaler', MinMaxScaler()),

])

num_tr = num_pipeline.fit_transform(x_train[correlation_num])
num_tr

for i in correlation_cat_ordinal:
    unique = data_final[i].unique()
    print(i,unique)

cat_pipeline = Pipeline([

    ('Encoder',OrdinalEncoder(categories=[
                            [' 36 months',' 60 months' ],
                            ['A','B','C','D','E','F','G' ],
                            ['n','y'],
                            ['f' ,'w']
                        ]))
])

cat_tr = cat_pipeline.fit_transform(x_train[correlation_cat_ordinal])
cat_tr

cat_pipeline2 = Pipeline([
    ('Encoder',OneHotEncoder(sparse=False))
])

cat_tr2 = cat_pipeline2.fit_transform(x_train[correlation_cat_non_ordinal])
cat_tr2

prep = ColumnTransformer([
    ('num',num_pipeline,correlation_num),
    ('cat_ordinal',cat_pipeline,correlation_cat_ordinal),
    ('cat_non_ordinal',cat_pipeline2,correlation_cat_non_ordinal),

])

prep

x_train_new = prep.fit_transform(x_train)
x_train_new = pd.DataFrame(x_train_new)
x_train_new

x_test_new = prep.transform(x_test)
x_test_new = pd.DataFrame(x_test_new)
x_test_new

"""# Modelling"""

knn = KNeighborsClassifier()
dt = DecisionTreeClassifier(random_state=12)
rf = RandomForestClassifier(random_state=12)
ada_boost = AdaBoostClassifier(random_state=12)

"""## KNN"""

x_train_knn = np.ascontiguousarray(x_train_new)
x_test_knn = np.ascontiguousarray(x_test_new)

knn.fit(x_train_knn,y_train)

y_train_predict_knn = knn.predict(x_train_knn)
y_test_predict_knn = knn.predict(x_test_knn)

print('------Clasification Report KNN Train-------')
print(classification_report(y_train,y_train_predict_knn))

print('')
print('------Clasification Report KNN Test-------')
print(classification_report(y_test,y_test_predict_knn))

ConfusionMatrixDisplay.from_estimator( knn, x_test_knn, y_test)

"""## Decision Tree"""

dt.fit(x_train_new,y_train)

y_train_predict_dt = dt.predict(x_train_new)
y_test_predict_dt = dt.predict(x_test_new)

print('------Clasification Report Decision Tree Train-------')
print(classification_report(y_train,y_train_predict_dt))

print('')
print('------Clasification Report Decision Tree Test-------')
print(classification_report(y_test,y_test_predict_dt))

ConfusionMatrixDisplay.from_estimator( dt, x_test_new, y_test)

"""## Random Forest"""

rf.fit(x_train_new,y_train)

y_train_predict_rf = rf.predict(x_train_new)
y_test_predict_rf = rf.predict(x_test_new)

print('------Clasification Report Random Forest Train-------')
print(classification_report(y_train,y_train_predict_rf))

print('')
print('------Clasification Report Random Forest Test-------')
print(classification_report(y_test,y_test_predict_rf))

ConfusionMatrixDisplay.from_estimator( rf, x_test_new, y_test)

"""## Ada Boost"""

ada_boost.fit(x_train_new,y_train)

y_train_predict_ada_boost = ada_boost.predict(x_train_new)
y_test_predict_ada_boost = ada_boost.predict(x_test_new)

print('------Clasification Report Ada Boost Train-------')
print(classification_report(y_train,y_train_predict_ada_boost))

print('')
print('------Clasification Report Ada Boost Test-------')
print(classification_report(y_test,y_test_predict_ada_boost))

ConfusionMatrixDisplay.from_estimator( ada_boost, x_test_new, y_test)

"""# Cross Validation"""

def cross_val (model):

    accuracy_train_cross_val = cross_val_score(model,
                                        x_train_new,
                                        y_train,
                                        cv=5,
                                        scoring="accuracy")

    print('----Cross Validation',model,'---- ')
    print('accuracy Score - All - Cross Validation  : ', accuracy_train_cross_val)
    print('accuracy Score - Mean - Cross Validation : ', accuracy_train_cross_val.mean())
    print('accuracy Score - Std - Cross Validation  : ', accuracy_train_cross_val.std())
    print('accuracy Score - Range of Test-Set       : ', (accuracy_train_cross_val.mean()-accuracy_train_cross_val.std()) , '-', (accuracy_train_cross_val.mean()+accuracy_train_cross_val.std()))

cross_val(knn)

cross_val(dt)

cross_val(rf)

cross_val(ada_boost)

"""# Hyperparameter Tuning"""

param = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

random_search = RandomizedSearchCV(estimator=rf, param_distributions=param, n_iter=10, cv=3, scoring='accuracy', n_jobs=-1, random_state=12)

random_search.fit(x_train_new, y_train)

print("Best Parameters:", random_search.best_params_)

best_model = random_search.best_estimator_
accuracy = best_model.score(x_test_new, y_test)
print(f"Best Model Accuracy: {accuracy:.2f}")

y_train_predict_best_rf = best_model.predict(x_train_new)
y_test_predict_best_rf = best_model.predict(x_test_new)

print('------Clasification Report Random Forest Best Train-------')
print(classification_report(y_train,y_train_predict_best_rf))

print('')
print('------Clasification Report Random Forest Best Test-------')
print(classification_report(y_test,y_test_predict_best_rf))

ConfusionMatrixDisplay.from_estimator( best_model, x_test_new, y_test)

"""# Model Final"""

#create a new default table to later compare with the default f1 score test values ​​and those already using random seach
all_reports_rf = {}
def performance_report(all_reports_rf, y_train, y_train_predict_rf, y_test, y_test_predict_rf, name):
  score_reports = {
      'train - precision' : precision_score(y_train, y_train_predict_rf,average='micro'),
      'train - recall' : recall_score(y_train, y_train_predict_rf,average='micro'),
      'train - accuracy' : accuracy_score(y_train, y_train_predict_rf),
      'train - f1_score' : f1_score(y_train, y_train_predict_rf,average='micro'),
      'test - precision' : precision_score(y_test, y_test_predict_rf,average='micro'),
      'test - recall' : recall_score(y_test, y_test_predict_rf,average='micro'),
      'test - accuracy_score' : accuracy_score(y_test, y_test_predict_rf),
      'test - f1_score' : f1_score(y_test, y_test_predict_rf,average='micro'),
  }
  all_reports_rf[name] = score_reports
  return all_reports_rf

all_reports_rf = performance_report(all_reports_rf, y_train, y_train_predict_rf, y_test, y_test_predict_rf, 'Baseline (Default Hyperparameter)')
pd.DataFrame(all_reports_rf)

all_reports_rf = performance_report(all_reports_rf, y_train, y_train_predict_best_rf, y_test, y_test_predict_best_rf, 'After HyperParameter Tuning')
pd.DataFrame(all_reports_rf)

"""Based on hyperparamter tuning test on RandomForest Classifier, the best model that we can use is baseline model (default model/before hyperparameter tuning).

# Model Saving
"""

with open('pipeline_preprocessing.pkl', 'wb') as file_1:
  pickle.dump(prep, file_1)

with open('model_rf_best.pkl', 'wb') as file_2:
  pickle.dump(best_model, file_2)

with open('list_num_columns.txt', 'w') as file_3:
  file_3.write(str(correlation_num))

with open('list_cat_columns_ordinal.txt', 'w') as file_4:
  file_4.write(str(correlation_cat_ordinal))

with open('list_cat_columns_non_ordinal.txt', 'w') as file_5:
  file_5.write(str(correlation_cat_non_ordinal))